import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sqlalchemy import create_engine, text
from sklearn.cluster import KMeans
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
import time
import sys
import math

# --- CONFIG & LOGGING ---
def thinking_log(message):
    sys.stdout.write(f"\rüß† AI: {message}" + " " * 30)
    sys.stdout.flush()
    time.sleep(0.05)

def process_log(step, message):
    print(f"\n   [B∆∞·ªõc {step}] ‚û§ {message}")
    time.sleep(0.2)

db_connection_str = 'mysql+pymysql://root:@127.0.0.1/elearning'
db_connection = create_engine(db_connection_str)

print("\n" + "="*60)
print("   üöÄ AI ENGINE v3.2: FINAL LOGIC FIX")
print("="*60 + "\n")

# --- PHASE 1: DATA MINING ---
thinking_log("ƒêang qu√©t l·ªô tr√¨nh h·ªçc t·∫≠p...")

query = """
SELECT 
    u.id as user_id,
    u.name,
    (SELECT COUNT(*) FROM learning_logs WHERE user_id = u.id) as login_count,
    COALESCE((SELECT AVG(score) FROM lesson_submissions WHERE user_id = u.id), 0) as avg_score,
    (SELECT COUNT(*) FROM lesson_submissions WHERE user_id = u.id AND score IS NOT NULL) as scored_lessons_count,
    
    (
        SELECT COUNT(l.id)
        FROM lessons l
        JOIN chapters c ON l.chapter_id = c.id
        JOIN enrollments e2 ON c.course_id = e2.course_id
        WHERE e2.user_id = u.id
    ) as total_assigned,
    
    (SELECT COUNT(*) FROM lesson_submissions WHERE user_id = u.id AND status = 'completed') as completed_lessons,
    
    DATEDIFF(NOW(), (SELECT MAX(created_at) FROM learning_logs WHERE user_id = u.id)) as days_since_last_login,

    -- T√åM B√ÄI TI·∫æP THEO
    (
        SELECT CONCAT(l.title, ' (M√¥n: ', co.title, ')')
        FROM lessons l
        JOIN chapters c ON l.chapter_id = c.id
        JOIN courses co ON c.course_id = co.id
        JOIN enrollments e3 ON co.id = e3.course_id
        WHERE e3.user_id = u.id
        AND l.id NOT IN (SELECT lesson_id FROM lesson_submissions WHERE user_id = u.id AND status = 'completed')
        ORDER BY l.id ASC
        LIMIT 1
    ) as next_lesson_title

FROM users u
WHERE u.role = 'student'
"""

df = pd.read_sql(query, db_connection)
df = df.fillna(0)
df['next_lesson_title'] = df['next_lesson_title'].replace(0, "Kh√¥ng c√≤n b√†i m·ªõi")

# Feature Engineering
df['progress_pct'] = df.apply(lambda x: min(100, (x['completed_lessons']/x['total_assigned']*100)) if x['total_assigned']>0 else 0, axis=1)
df['days_since_last_login'] = df['days_since_last_login'].fillna(365)
df['recency_score'] = df['days_since_last_login'].apply(lambda x: 100 if x <= 2 else (max(0, 100 - x*2)))
max_login = df['login_count'].max() if df['login_count'].max() > 0 else 1
df['effort_score'] = (df['login_count'] / max_login * 50) + (df['progress_pct'] / 100 * 50)

process_log(1, f"ƒê√£ t·∫£i d·ªØ li·ªáu c·ªßa {len(df)} sinh vi√™n.")

# --- PHASE 2: CLUSTERING ---
thinking_log("ƒêang ph√¢n lo·∫°i nƒÉng l·ª±c...")
features = ['avg_score', 'progress_pct', 'effort_score', 'recency_score']
X = df[features]
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

kmeans = KMeans(n_clusters=4, random_state=42)
df['cluster'] = kmeans.fit_predict(X_scaled)
iso_forest = IsolationForest(contamination=0.05, random_state=42)
df['is_anomaly'] = iso_forest.fit_predict(X_scaled)

# --- PHASE 3: THE MENTOR LOGIC (FIXED) ---
thinking_log("ƒêang t√≠nh to√°n chi·∫øn l∆∞·ª£c (ƒê√£ s·ª≠a l·ªói Logic)...")

def prescribe_strategy(row):
    current_gpa = row['avg_score']
    n_lessons = row['scored_lessons_count']
    next_lesson = row['next_lesson_title']
    recency = row['recency_score']

    # 1. Check Anomalies / Dropout first
    if recency < 20:
        return "B√ìNG MA H·ªåC ƒê∆Ø·ªúNG", "High", "C·∫¢NH B√ÅO: B·∫°n ƒë√£ bi·∫øn m·∫•t qu√° l√¢u. H√£y ƒëƒÉng nh·∫≠p l·∫°i ngay!"
    if row['is_anomaly'] == -1:
        return "C·∫¶N KI·ªÇM TRA", "High", "H√†nh vi h·ªçc t·∫≠p b·∫•t th∆∞·ªùng. Vui l√≤ng li√™n h·ªá gi·∫£ng vi√™n."

    # 2. X·ª¨ L√ù TR∆Ø·ªúNG H·ª¢P H·∫æT B√ÄI (QUAN TR·ªåNG: FIX L·ªñI ·ªû ƒê√ÇY)
    if next_lesson == "Kh√¥ng c√≤n b√†i m·ªõi":
        if current_gpa < 5.0:
            return "C·∫¢NH B√ÅO R·ªöT M√îN", "High", f"B·∫°n ƒë√£ ho√†n th√†nh h·∫øt b√†i t·∫≠p nh∆∞ng ƒëi·ªÉm trung b√¨nh ch·ªâ ƒë·∫°t {current_gpa:.1f} (< 5.0). Vui l√≤ng ƒëƒÉng k√Ω h·ªçc l·∫°i."
        elif current_gpa < 8.0:
            return "H·ªåC VI√äN TRUNG B√åNH", "Medium", f"Ch√∫c m·ª´ng b·∫°n ƒë√£ ho√†n th√†nh kh√≥a h·ªçc v·ªõi GPA {current_gpa:.1f}. K·∫øt qu·∫£ m·ª©c Kh√°."
        else:
            return "CHI·∫æN TH·∫¶N H·ªåC T·∫¨P", "Low", f"Xu·∫•t s·∫Øc! B·∫°n ƒë√£ t·ªët nghi·ªáp kh√≥a h·ªçc v·ªõi s·ªë ƒëi·ªÉm ·∫•n t∆∞·ª£ng: {current_gpa:.1f}."

    # 3. T√≠nh to√°n m·ª•c ti√™u cho ng∆∞·ªùi C√íN b√†i h·ªçc
    # --- NH√ìM Y·∫æU ---
    if current_gpa < 5.0:
        target_gpa = 5.0
        needed_score = (target_gpa * (n_lessons + 1)) - (current_gpa * n_lessons)
        needed_score = math.ceil(needed_score * 10) / 10
        
        if needed_score > 10:
            return "NGUY C∆† R·∫§T CAO", "High", f"Kh√≥ c·ª©u v√£n! B·∫°n c·∫ßn h∆°n 10 ƒëi·ªÉm ·ªü b√†i **'{next_lesson}'** ƒë·ªÉ qua m√¥n. H√£y g·∫∑p gi·∫£ng vi√™n ngay."
        elif needed_score <= 0:
             return "C·∫¶N C√ô B√ô TH√îNG MINH", "Medium", f"C·ªë l√™n! Ch·ªâ c·∫ßn ho√†n th√†nh b√†i **'{next_lesson}'** l√† k√©o l·∫°i ƒë∆∞·ª£c ƒëi·ªÉm s·ªë."
        else:
            return "C·∫¢NH B√ÅO R·ªöT M√îN", "High", f"M·ª•c ti√™u s·ªëng c√≤n: Ph·∫£i ƒë·∫°t t·ªëi thi·ªÉu **{needed_score} ƒëi·ªÉm** ·ªü b√†i **'{next_lesson}'** ƒë·ªÉ v√†o v√πng an to√†n."

    # --- NH√ìM KH√Å ---
    elif current_gpa < 8.0:
        target_gpa = 8.0
        needed_score = (target_gpa * (n_lessons + 1)) - (current_gpa * n_lessons)
        needed_score = math.ceil(needed_score * 10) / 10

        if needed_score > 10:
            return "H·∫†T GI·ªêNG TI·ªÄM NƒÇNG", "Medium", f"C·∫ßn n·ªó l·ª±c r·∫•t l·ªõn ƒë·ªÉ l√™n lo·∫°i Gi·ªèi. H√£y c·ªë h·∫øt s·ª©c ·ªü b√†i **'{next_lesson}'**."
        elif needed_score <= 0:
            return "TI·ªÄM NƒÇNG L·ªöN", "Low", f"Phong ƒë·ªô ·ªïn ƒë·ªãnh. H√£y ho√†n th√†nh t·ªët b√†i **'{next_lesson}'**."
        else:
            return "TI·ªÄM NƒÇNG L·ªöN", "Low", f"Th·ª≠ th√°ch: ƒê·∫°t **{needed_score} ƒëi·ªÉm** b√†i **'{next_lesson}'** ƒë·ªÉ thƒÉng h·∫°ng l√™n Gi·ªèi (8.0)."

    # --- NH√ìM GI·ªéI ---
    else:
        return "CHI·∫æN TH·∫¶N H·ªåC T·∫¨P", "Low", f"ƒê·∫≥ng c·∫•p! H√£y chinh ph·ª•c b√†i **'{next_lesson}'** ƒë·ªÉ gi·ªØ v·ªØng v·ªã tr√≠ d·∫´n ƒë·∫ßu."

results = df.apply(prescribe_strategy, axis=1, result_type='expand')
df[['persona', 'risk_level', 'recommendation']] = results

process_log(3, "ƒê√£ t√≠nh to√°n xong chi·∫øn l∆∞·ª£c h·ªçc t·∫≠p.")

# --- PHASE 4: SAVE ---
thinking_log("ƒêang l∆∞u k·∫øt qu·∫£ v√†o Database...")

# (Ph·∫ßn v·∫Ω bi·ªÉu ƒë·ªì gi·ªØ nguy√™n, l∆∞·ª£c b·ªè cho g·ªçn)
plt.figure(figsize=(12, 7))
sns.set_style("whitegrid")
sns.scatterplot(data=df, x='effort_score', y='avg_score', hue='persona', style='risk_level', size='progress_pct', sizes=(50, 400), palette='viridis', alpha=0.9, edgecolor='black')
plt.title('B·∫¢N ƒê·ªí CHI·∫æN L∆Ø·ª¢C H·ªåC T·∫¨P (AI MENTOR FIXED)', fontsize=16, fontweight='bold')
plt.xlabel('N·ªó l·ª±c'), plt.ylabel('GPA')
plt.savefig('public/ai_analysis_chart.png', dpi=100)

with db_connection.connect() as conn:
    conn.execute(text("TRUNCATE TABLE student_predictions"))
    conn.commit()

output_data = df[['user_id', 'avg_score', 'login_count', 'progress_pct', 'risk_level', 'recommendation']]
output_data.columns = ['user_id', 'avg_score', 'login_count', 'completion_rate', 'risk_level', 'ai_recommendation']
output_data.to_sql('student_predictions', db_connection, if_exists='append', index=False)

print("\n" + "="*60)
print(f"‚úÖ AI ƒê√É HO√ÄN T·∫§T. Logic 'H·∫øt b√†i' ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω.")
print("="*60 + "\n")